{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ace4e409",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center;font-size:250%\">F I X E R  1</h1>\n",
    "\n",
    "This notebook takes 1D spectra from the red and blue arms reduced with the DRAGONS pipeline, **combines multiple exposures** (if any), **normalizes** the spectra with an automatic continuum fit or a user-defined continuum, **calculates the radial velocity** of the object by performing a cross correlation with a metal-poor template over multiple wavelength ranges, and **radial velocity corrects** the spectrum. Additionally, there is the option to perform a barycentric velocity correction.  \n",
    "\n",
    "<span style=\"font-size:150%\"> **Inputs:** </span><br>\n",
    "The 1D spectra (red and blue) from the \\_dragons output files. Please note that this fixer should be applied once per observation \"epoch\". **E.g.: even if there are two observations of a single star in one night, such as S202405040241.fits and S202405040242.fits, they must each be radial velocity corrected separately, and only combined at the very last step.**\n",
    "\n",
    "If your `[..]_dragons.fits` data comes directly from the **Gemini Archive**, it must first be unzipped and then reduced with dragons. Unzip the tar file with `tar -xvf gemini_data.tar`. \n",
    "\n",
    "Then, unzip the individual .bz2 files with `bzip2 -d *.bz2`. \n",
    "\n",
    "To finally reduce the .fits files into .dat files, activate DRAGONS in the command line: \n",
    "\n",
    "`source ~/.bashrc`\n",
    "\n",
    "`conda activate` \n",
    "\n",
    "`conda activate dragons`\n",
    "\n",
    "Finally, apply the `reduce -r write1DSpectra [fits filename or *.fits] -p var=True ` command to your data (i.e. the .dat files **must** include variance). For example, all files for your observations are labelled as:   \n",
    "- S20240504S0241_blue00?_dragons.fits\n",
    "- S20240504S0241_red00?_dragons.fits\n",
    "- S20240504S0241_blue00?_dragons_00?.dat\n",
    "- S20240504S0241_red00?_dragons_00?.dat\n",
    "\n",
    "Where '?' in red00? indicates the exposure number and '?' in _00?.dat indicates the IFU. *Note: If you have a single-IFU observation, you will have additional _002.dat files, which are the sky files. If your observations come from the dual-IFU mode, the sky files will instead be denoted with _003.dat. They are not needed for any analysis in this notebook.*\n",
    "\n",
    "Note that the original \\_dragons.fits files are only required from this point on if the data has not been barycentric corrected. This is likely only the case for commissioning data..\n",
    "\n",
    "<span style=\"font-size:120%\"> **File Organization:** </span><br>\n",
    "\n",
    "To keep files organized, it may be useful to store all your stars data in a folder labeled with the first series of numbers common to all your star's files; i.e S20240504S0241. \n",
    "\n",
    "Alternatively, if your star has **multiple epoch observations** (i.e., multiple file names for the same star), it may be more useful to label the directory with the **star id**, and store all of the files in there.\n",
    "\n",
    "<br />\n",
    "\n",
    "<span style=\"font-size:150%\"> **Outputs:** </span><br>\n",
    "By default, this notebook saves its output files in the same folder in which it finds the input files. The labels also resemble the input files in structure in order to easily identify which observation date and number the reduction belong to. The outputs are:\n",
    "- An .xyz and a .dat file of the combined exposures (1 x blue, 1 x red): \n",
    "    - S20240504S0241_00?_blue.xyz / .bin \n",
    "    - S20240504S0241_00?_red.xyz / .bin\n",
    "- An .xyz file of the normalized spectrum (2 x blue, 1 x red):\n",
    "    - S20240504S0241_00?_blue1_norm.xyz \n",
    "    - S20240504S0241_00?_blue2_norm.xyz \n",
    "    - S20240504S0241_00?_red_norm.xyz \n",
    "- A .txt file with the radial velocities:\n",
    "    - S20240504S0241_00?_radialVelocities.txt\n",
    "- An .xyz file with the radial velocity corrected, normalized spectrum (1 x blue, 1 x red):\n",
    "    - S20240504S0241_00?_blue_normrv.xyz\n",
    "    - S20240504S0241_00?_red_normrv.xy\n",
    "\n",
    "where '?' indicates the IFU<br>\n",
    "This notebook does <u>not</u> combine the blue and the red arms. One technique to combine these arms is described at the end of the notebook.\n",
    "\n",
    "<span style=\"background-color: #cdd5c1\">  </span>\n",
    "\n",
    "<span style=\"font-size:110%\"> **Required installations:** </span><br>\n",
    "This notebook requires python modules `emcee` and `corner` which can be installed with `pip`. As well, the DRAGONS conda package required for 1D spectrum conversion may be found [here](https://github.com/GeminiDRSoftware/DRAGONS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3091d686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary modules and packages \n",
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from scipy import interpolate\n",
    "from datetime import datetime, date, time, timedelta\n",
    "import astropy.coordinates as astrocoord\n",
    "from astropy.time import Time\n",
    "from astropy.io import fits\n",
    "from astropy import units as u\n",
    "import os \n",
    "import glob\n",
    "import itertools\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, './') # POINTING TO THE FIXER DIRECTORY, OR WHERE apo_tools IS STORED\n",
    "from apo_tools.spec_tools import Spectrum\n",
    "from apo_tools.turbospec_tools import SpectrumTS\n",
    "\n",
    "sys.path.insert(0, './apogee/')\n",
    "import external.doppler.doppler as doppler\n",
    "\n",
    "module_path = os.path.join('./asap_lib/')\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import spectra as sa\n",
    "\n",
    "GEMINI_SOUTH_LOC=astrocoord.EarthLocation.from_geodetic((-70,44,12.096),(-30,14,26.700),height=2722.,ellipsoid='WGS84')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cf6df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some necessary functions\n",
    "class SpecNormRV(Spectrum):\n",
    "        \n",
    "    def add_template(self, template):\n",
    "        self.original_template = template\n",
    "        self._interpolate_template()\n",
    "            \n",
    "    def rv_correct(self, wave_range=None, vel_range=None, inspect=False, \n",
    "                   shift_wavelength=True, fill_nan=True, fill_value=1):\n",
    "        \n",
    "        if wave_range is None:\n",
    "            wave_range = [3500, 10600]  \n",
    "        if vel_range is None:\n",
    "            vel_range = [-500, 500]\n",
    "        \n",
    "        inwave = self.wavelength\n",
    "        intemp = self.template.flux\n",
    "        inspec = self.flux\n",
    "        inerr = np.sqrt(self.variance)\n",
    "\n",
    "        if fill_nan:\n",
    "            inspec = np.array(inspec)\n",
    "            inspec[~np.isfinite(inspec)] = 1\n",
    "            inerr[~np.isfinite(inspec)] = 1.e6\n",
    "\n",
    "        wave_mask = (inwave > wave_range[0]) & (inwave < wave_range[1])\n",
    "        out = doppler.rv.specxcorr(wave=inwave[wave_mask],\n",
    "                                   tempspec=intemp[wave_mask],\n",
    "                                   obsspec=inspec[wave_mask], \n",
    "                                   obserr=inerr[wave_mask],\n",
    "                                   plot=inspect,\n",
    "                                   maxlag=vel_range)\n",
    "        \n",
    "        self.rv = out['vrel'][0]\n",
    "        self.rv_err = out['vrelerr'][0]\n",
    "        \n",
    "        if shift_wavelength:\n",
    "            self.wavelength=self.vel_shift(-1.*self.rv)\n",
    "            self._interpolate_template()\n",
    "            \n",
    "    def barycenter_correction(self, ra, dec, date_obs, utstart, exptime, verbose=False):\n",
    "        # Set up a SkyCoord for this ad\n",
    "        sc = astrocoord.SkyCoord(ra, dec,unit=(u.hr, u.deg, ))\n",
    "\n",
    "        # Compute central time of observation\n",
    "        dt_start = datetime.combine(\n",
    "            datetime.strptime(date_obs, '%Y-%m-%d').date(),\n",
    "            datetime.strptime(utstart, '%H:%M:%S').time(),\n",
    "        )\n",
    "\n",
    "        dt_midp = dt_start + timedelta(\n",
    "            seconds=exptime/2.0\n",
    "        )\n",
    "        dt_midp = Time(dt_midp)\n",
    "\n",
    "        # Vanilla AstroPy Implementation\n",
    "        corr_fact = sc.radial_velocity_correction('barycentric',obstime=dt_midp,location=GEMINI_SOUTH_LOC)\n",
    "        corr_fact = corr_fact.to(u.km / u.s)\n",
    "        self.rv_bary = self.rv + corr_fact.value\n",
    "            \n",
    "        if verbose:\n",
    "            print(f'Correction Factor = {corr_fact:.2f}')\n",
    "            print(f'RV = {self.rv:.2f}')\n",
    "            print(f'Barycentric RV = {self.rv_bary:.2f}')\n",
    "        \n",
    "    def _interpolate_template(self):\n",
    "        ip=interpolate.InterpolatedUnivariateSpline(self.original_template.wavelength,self.original_template.flux,k=3,ext=0)\n",
    "        self.template = Spectrum(self.wavelength,ip(self.wavelength))        \n",
    "\n",
    "# ----------------------------------------------------         \n",
    "def comb_blue(blue1, blue2):\n",
    "    b1w = np.array(blue1['wavelength']) ; b1f = np.array(blue1['flux']) ; b1v = np.array(blue1['variance']) ;\n",
    "    b2w = np.array(blue2['wavelength']) ; b2f = np.array(blue2['flux']) ; b2v = np.array(blue2['variance']) ;\n",
    "    wave = np.concatenate([b1w,b2w]) ; flux = np.concatenate([b1f,b2f]) ; varn = np.concatenate([b1v,b2v])\n",
    "    return wave,flux,varn\n",
    "    \n",
    "#-----------------------------------------------------\n",
    "def comment_out_header(spath):\n",
    "    with open(spath, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    for i in range(3): # Check if the column names are in the top 3 lines, and comment them out.\n",
    "        line = lines[i]\n",
    "        if ('#' not in line) and ('wavelength data variance' in line):\n",
    "            os.system(f\"sed -i '{i+1}s/wavelength data variance/# wavelength data variance/' {spath}\")\n",
    "            \n",
    "        elif ('#' not in line) and ('wavelength flux variance' in line):\n",
    "            os.system(f\"sed -i '{i+1}s/wavelength flux variance/# wavelength flux variance/' {spath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bf402a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## These are extra wavelength regions to see how the\n",
    "#  RV corrections vary across the spectrum.\n",
    "#  Feel free to update!!\n",
    "\n",
    "wavelengths_dict = {\n",
    "    'blue1':   [4000, 4400], \n",
    "    'blue2':   [4400, 4800],\n",
    "    'blue3':   [4800, 5300],\n",
    "    'blue12':  [4000, 4800],\n",
    "    'blue23':  [4400, 5300],\n",
    "    'blue123': [4000, 5300], \n",
    "    \n",
    "    'red1':    [5300, 5800],\n",
    "    'red2':    [6000, 6500],\n",
    "    'red3':    [6600, 7500],\n",
    "    'red12':   [5300, 6500],\n",
    "    'red23':   [6000, 7500],\n",
    "    'red123':  [5300, 7500],\n",
    "}\n",
    "\n",
    "# Corrections made around specific lines\n",
    "wavelengths_lines_dict = {\n",
    "    'blue_CaHK': [3800, 4000],\n",
    "    'blue_Hd':   [4000, 4200],\n",
    "    'blue_Hg':   [4200, 4400],\n",
    "    'blue_Hb':   [4700, 4900],\n",
    "    'blue_MgB':  [5100, 5300],\n",
    "     \n",
    "    'red_NaD':   [5800, 6000],\n",
    "    'red_Ha':    [6500, 6700],\n",
    "    'red_CaT':   [8400, 8700],\n",
    "    'red_CaT2':  [8525, 8575]\n",
    "}\n",
    "\n",
    "def correct_RV_at_wrange(wrange, bary=False, bfull=False):\n",
    "    \"\"\"\n",
    "    For the latter half of this notebook: Correct for the radial velocity,\n",
    "    at a specified wavelength range.\n",
    "    \n",
    "    Note: There are a few GLOBAL variables in this notebook. Please\n",
    "    be careful if changing any variable names.\n",
    "    \"\"\"\n",
    "    if max(wrange) <= 5300: # Aka: if wrange spans the blue arm\n",
    "        if min(wrange) >= 4400:\n",
    "            spectrum = cand_blue2\n",
    "        elif max(wrange) <= 4400:\n",
    "            spectrum = cand_blue1\n",
    "        else:\n",
    "            spectrum = cand_blue\n",
    "    else:\n",
    "        spectrum = cand_red\n",
    "    \n",
    "    if bfull == True:\n",
    "        spectrum = cand_blue\n",
    "\n",
    "    spectrum.rv_correct(wave_range=wrange,  inspect = False, shift_wavelength=False)\n",
    "    \n",
    "    if bary == True:\n",
    "        if max(wrange) <= 5300:\n",
    "            spectrum.barycenter_correction(*blue_bary_data)\n",
    "        else:\n",
    "            spectrum.barycenter_correction(*red_bary_data)\n",
    "        return spectrum.rv_bary, spectrum.rv_err\n",
    "    \n",
    "    return spectrum.rv, spectrum.rv_err\n",
    "\n",
    "def correct_regions(specific_lines=False, bary=False):\n",
    "    correction_dict = wavelengths_dict\n",
    "    if specific_lines == True:\n",
    "        correction_dict = wavelengths_lines_dict\n",
    "    \n",
    "    for key in correction_dict.keys():\n",
    "        wrange = correction_dict[key]\n",
    "          \n",
    "        rv, rv_err = correct_RV_at_wrange(wrange, bary)\n",
    "        \n",
    "        print(f'RV correction: {key.ljust(10)} \\t {wrange}: \\t {rv} \\t± {rv_err}')\n",
    "\n",
    "    print('\\n')\n",
    "    return None\n",
    "\n",
    "def save_RV(lines, bary=False):\n",
    "    # lines is a list of wavelength 'keys', \n",
    "    #  e.g. lines = ['blue123', 'red_Ha']\n",
    "    if not isinstance(lines, list):\n",
    "        raise ValueError(f'Input should be a list of key(s)')\n",
    "    \n",
    "    full_dict = wavelengths_dict.copy()\n",
    "    full_dict.update(wavelengths_lines_dict)\n",
    "    \n",
    "    output = \"\"\n",
    "    \n",
    "    for line in lines:\n",
    "        if 'range' in line:\n",
    "            bfull = False\n",
    "            wrange = formal_corrections[line]\n",
    "            if line == 'blue_range':\n",
    "                bfull = True\n",
    "            \n",
    "            rv, rv_err = correct_RV_at_wrange(wrange, bary, bfull)\n",
    "\n",
    "        elif line.strip() not in full_dict.keys():\n",
    "            raise ValueError(f'Please specify valid lines to save, {line.strip()} is not a valid region.')\n",
    "        else:\n",
    "            wrange = full_dict[line.strip()]\n",
    "            rv, rv_err = correct_RV_at_wrange(wrange, bary)\n",
    "            \n",
    "        output += f'{line[0].capitalize() + line[1:]}:'.ljust(15) + f'\\t{rv} \\t± {rv_err}\\n'\n",
    "    \n",
    "    output += '\\n'\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf110bba",
   "metadata": {},
   "source": [
    "# Indicate file path\n",
    "<span style=\"text-align:left; background-color: #cdd5c1\"> This cell requires user input</span><br>\n",
    "This cell allows the rest of the notebook to find/save files. Indicate the observation number (that which includes the date) under `star`, the IFU (usually \\_001 or \\_002) in `num`, the path to the FIXER_1 folder in your directories in `path`, and the path to the folder containing your star/observation's data *within* the FIXER_1 folder in `fipath`.\n",
    "\n",
    "The paths and file names are broken down in this manner because each component is used separately somewhere in the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e940b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indicate the object and confirm file path.\n",
    "\n",
    "star = 'S###############' # Gemini Filename\n",
    "num  = '_001' # IFU\n",
    "end  = '_dragons' + num  \n",
    "\n",
    "path =  f'/your_path_here/' # Points to /FIXER_1.\n",
    "fipath = path  + f'STAR_DIRECTORY/' # This is the same path where output files will be saved,\n",
    "                                    #   and where data is stored\n",
    "spath  = fipath + star  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e7bfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "spath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7d0e5e",
   "metadata": {},
   "source": [
    "## NOTE: If you only want to run RV corrections, RUN UP TO THIS POINT and continue at \"Calculate and Correct for Radial Velocity\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e39e89",
   "metadata": {},
   "source": [
    "# Combine Exposures\n",
    "The following cell combines multiple exposures (if any) of each arm for the indicated IFU in `num` and saves the stack as both .bin and .xyz files. This cell must be run even if there is only one exposure per arm. \n",
    "\n",
    "This cell will indicate whether the notebook was able to **find** and **save** your exposures. If not, adjust the cell above so it can. \n",
    "<br>If an ERROR message appears indicating the first line of the .dat file can't be read, go into the file and comment out the line `wavelength flux variance`, but **don't delete it**; have it be: `# wavelength flux variance`. This should be done by the script automatically, but this message remains just in case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba25b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "for camera in ['blue', 'red']:\n",
    "    \n",
    "    naming = '*{}*'+ end + '.dat'\n",
    "    condition = naming.format(camera)\n",
    "    obs = glob.glob(spath+condition)\n",
    "    \n",
    "    print('Found {} exposure(s) to combine: '.format(len(obs)))\n",
    "    print( * obs, sep = \"\\n\")\n",
    "\n",
    "    # --------------------------------\n",
    "    waves  = []\n",
    "    fluxes = []\n",
    "    varian = []\n",
    "\n",
    "    for item in obs:\n",
    "        comment_out_header(item) # Comments out the wavelength data variance header automatically.\n",
    "        wave, flux, var = sa.read_spec(item, ftype ='xyz')\n",
    "\n",
    "        waves.append(wave)\n",
    "        fluxes.append(flux)\n",
    "        varian.append(var)\n",
    "    \n",
    "    # --------------------------------\n",
    "    pairs =  list(itertools.combinations(range(len(waves)), 2))\n",
    "\n",
    "    value = True\n",
    "    for pair in pairs:\n",
    "        value = np.array_equal(waves[pair[0]], waves[pair[1]])\n",
    "        if value == False:\n",
    "            print('Wavelength arrays not equivalent. Do not proceed')\n",
    "            break\n",
    "    \n",
    "    if value == False:\n",
    "        break\n",
    "\n",
    "    if len(waves) > 0:\n",
    "        # -------------------------------- Median Combine flux and combine error with Poisson statistics \n",
    "        finalWave = waves[0]\n",
    "        finalFlux = np.median(fluxes,axis = 0)\n",
    "        #finalErr = np.zeros(len(finalWave))\n",
    "        finalErr = np.sqrt( sum(i*i for i in varian) ) / len(waves)\n",
    "\n",
    "        # -------------------------------- Save the output as .xyz and .bin files \n",
    "        sa.write2xyz(finalWave, finalFlux, finalErr, spath +num+'_{}'.format(camera))\n",
    "        sa.write2bin(finalWave, finalFlux, finalErr, spath +num+'_{}'.format(camera))\n",
    "\n",
    "        print('Saved combination of {} {} camera image(s)'.format(len(waves), camera))\n",
    "        # --------------------------------\n",
    "\n",
    "    else:\n",
    "        print('No {} camera files found'.format(camera))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ed9c40",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### Patch NaN and Inf values   (OPTIONAL)\n",
    "Sometimes spectra have nan and inf values which can be difficult to work with. The following code will change all inf and nan flux values in a spectrum to a specified value (This can be performed at any stage ). <br>\n",
    "This cell is \"turned off\" by default but included just in case the user needs it."
   ]
  },
  {
   "cell_type": "raw",
   "id": "7ce43c36-b1a2-40ce-b879-c8f621180850",
   "metadata": {},
   "source": [
    "camera = 'blue'            # options are:'red' or 'blue'         \n",
    "ftyp   = 'bin'             # type of file we want to read \n",
    "\n",
    "# -------------------------------- \n",
    "# Path to the spectrum of the object \n",
    "specPath =  spath + f'{num}_{camera}.{ftyp}'  \n",
    "\n",
    "# -------------------------------- \n",
    "# Path to save result to\n",
    "savePath = spath + f'{num}_{camera}_patched' \n",
    "\n",
    "# -------------------------------- \n",
    "# Read in the spectrum\n",
    "w, f, e = sa.read_spec(specPath, ftype=ftyp)\n",
    "\n",
    "# -------------------------------- \n",
    "# Replace all inf and nan values with 0 and make error very large wherever you do that \n",
    "change_f, change_e = sa.spectrum_replaceNaN(f,e, fill_value=0, change_err=True, fill_error=1e99)\n",
    "\n",
    "# --------------------------------\n",
    "# Save the output as .xyz and .bin files \n",
    "sa.write2xyz( w, change_f,change_e, savePath )\n",
    "sa.write2bin( w, change_f,change_e, savePath )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd7a86f-b242-41f2-a9f6-67dacd29d1f5",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "__________\n",
    "\n",
    "# Normalization\n",
    "<span style=\"background-color: #cdd5c1\"> This routine requires user input </span><br>\n",
    "This section performs the normalization of the spectra. In order to achieve a better continuum estimation, the blue arm is split in two sections: blue1 spans the wavelength region [3700, 4405] Å while blue2 spans the region [4395, 5305] Å. The two sections of the blue arm are re-combined later.  \n",
    "\n",
    "\n",
    "The following cell reads each of the files separately, this means **you will run the routine at least three times** (making sure to save your favourite fits) in order to obtain a normalized red arm, a normalized blue1 section and a normalized blue2 section (i.e. there needs to be three output files). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c2c9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indicate the camera and number(if applicable)\n",
    "\n",
    "camera = 'blue'             # options are:'red' or 'blue'\n",
    "nblue  = '1'               # if blue, options are: '1' or '2' \n",
    "ftyp   = 'bin'             # type of file we want to read \n",
    "\n",
    "# -------------------------------------------------------------------------------\n",
    "\n",
    "fpath  = spath + f'{num}_{camera}.{ftyp}'  # Path to combined-exposures files\n",
    "\n",
    "# Read the files\n",
    "w, f, e = sa.read_spec(fpath, ftype = ftyp)\n",
    "\n",
    "# This selection crops off noisy ends and splits the blue spectra\n",
    "if camera == 'red':\n",
    "    w_min = 5295\n",
    "    w_max = 9500\n",
    "    colour = 'tab:orange'\n",
    "    contr  = 'tab:blue'\n",
    "\n",
    "elif camera == 'blue':\n",
    "    if nblue == '1':\n",
    "        w_min  = 3700     \n",
    "        w_max  = 4405    \n",
    "        colour = 'royalblue'\n",
    "        contr  = 'tab:orange'\n",
    "        \n",
    "    elif nblue == '2':\n",
    "        w_min  = 4395\n",
    "        w_max  = 5305\n",
    "        colour = 'tab:blue'\n",
    "        contr  = 'tab:orange'\n",
    "\n",
    "ind = np.where( (w >= w_min) & (w <= w_max ) )[0]\n",
    "\n",
    "wave = w[ind]\n",
    "flux = np.array(f[ind].flatten(), dtype='float32')\n",
    "error = np.array(e[ind].flatten(), dtype='float32')\n",
    "\n",
    "print(\"File being read:\\n\",fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c09177-0af8-40b6-b00b-726b120b0a6c",
   "metadata": {},
   "source": [
    "###  Auto Continuum normalization:\n",
    "Use the plots to visualize the continuum fit. **Adjust the smooth_kernel to change the shape of the continuum in the second plot and change the sigma variables** to move the fit up or down on the last plot. Works best for `red` and `blue2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65162480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indicate values for the following parameters and run the cell to perform the normalization\n",
    "\n",
    "if camera == 'red':\n",
    "    smooth_kernel = 2000   \n",
    "    sigma_lower = 1.5     \n",
    "    sigma_upper = 3       \n",
    "\n",
    "if camera == 'blue':\n",
    "    if nblue == '2':\n",
    "        smooth_kernel = 900    \n",
    "        sigma_lower = 1.5 # 1.1 \n",
    "        sigma_upper = 3       \n",
    "    \n",
    "    elif nblue == '1': \n",
    "        smooth_kernel = 400    \n",
    "        sigma_lower = 1.5       \n",
    "        sigma_upper = 3    \n",
    "\n",
    "norm, cont = sa.contnorm_filter(flux, smooth_kernel, mode='reflect')\n",
    "norm2 = sa.contnorm_sigclip(norm, sigma_lower, sigma_upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb6a56f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# These plots are to visualize the normalization\n",
    "%matplotlib notebook\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "#-------------------\n",
    "ax = plt.subplot( 411 )\n",
    "plt.title('Original Spectrum')\n",
    "plt.plot( wave, flux , color = colour)\n",
    "plt.grid(alpha=0.25)\n",
    "plt.xlabel('Wavelength')\n",
    "plt.ylabel('Flux')\n",
    "\n",
    "plt.ylim(-500,1500)\n",
    "\n",
    "#-------------------\n",
    "ax2 = plt.subplot( 412, sharex=ax )\n",
    "plt.title('Continuum Estimation via Filtering')\n",
    "\n",
    "plt.plot( wave, flux, label='Original Spectrum', color=colour)\n",
    "plt.plot( wave, cont, label='Estimated Continuum', color=contr)\n",
    "plt.grid(alpha=0.25)\n",
    "plt.legend(ncol=2)\n",
    "plt.xlabel('Wavelength')\n",
    "plt.ylabel('Flux')\n",
    "\n",
    "plt.ylim(-500,1500)\n",
    "\n",
    "#-------------------\n",
    "ax3 = plt.subplot( 413, sharex=ax )\n",
    "plt.title('Continuum Normalization via Filtering')\n",
    "\n",
    "plt.ylim(-2,3)\n",
    "\n",
    "plt.plot( wave, norm, label='Normalized Spectrum', color = colour)\n",
    "plt.grid(alpha=0.25)\n",
    "xmin, xmax = ax.get_xlim()\n",
    "plt.hlines(1,xmin,xmax, color=contr,zorder=5,alpha=0.5, label='1')\n",
    "plt.xlabel('Wavelength')\n",
    "plt.ylabel('Flux')\n",
    "plt.legend(ncol=2)\n",
    "\n",
    "#-------------------\n",
    "ax4 = plt.subplot( 414, sharex=ax )\n",
    "plt.title('Continuum Position Improvement via sigma-clipping')\n",
    "\n",
    "plt.plot( wave, norm2, label='Normalized Spectrum', color = colour)\n",
    "plt.grid(alpha=0.25)\n",
    "xmin, xmax = ax.get_xlim()\n",
    "plt.hlines(1,xmin,xmax, color=contr,zorder=5,alpha=0.5, label='1')\n",
    "plt.xlabel('Wavelength')\n",
    "plt.ylabel('Flux')\n",
    "\n",
    "plt.ylim(-1.5,3)\n",
    "\n",
    "#-------------------\n",
    "plt.legend(ncol=2)\n",
    "plt.subplots_adjust(hspace=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe25944a-5183-42ff-9f53-b6505a98570c",
   "metadata": {},
   "source": [
    "**OPTIONAL:** Save the result\n",
    "<br> Once you are satisfied with the auto-normalization, save the spectrum by running the following cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901d0c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "if camera == 'blue':\n",
    "    section = nblue\n",
    "else:\n",
    "    section = ''\n",
    "save_path = f'{fipath}{star}{num}_{camera}{section}_norm'\n",
    "\n",
    "print(len(error), len(wave), len(norm2))\n",
    "sa.write2xyz(wave, norm2, error, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2028507",
   "metadata": {},
   "source": [
    "# Manual Continuum Normalization, e.g. for CH 4320 band:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54e697e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = open(path + 'FIXER_1/' + 'norm/metal_poor_template.spec.convol').readlines()\n",
    "\n",
    "turbo_w = [ float(line.split()[0]) for line in lines ]\n",
    "turbo_f = [ float(line.split()[1]) for line in lines ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c38f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Initialize and create continuum\n",
    "%matplotlib notebook\n",
    "continuum = sa.drawContinuum(wave, flux)\n",
    "continuum.addReference(turbo_w, turbo_f)\n",
    "continuum.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba67470",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuum.disconnect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65ed773",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuum.Help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1950ad2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if camera == 'blue':\n",
    "    section = nblue\n",
    "else:\n",
    "    section = ''\n",
    "save_path = f'{fipath}{star}{num}_{camera}{section}_norm_manual'\n",
    "\n",
    "sa.write2xyz(wave, continuum.norm, error, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a727ce73",
   "metadata": {},
   "source": [
    "<br>Once you have saved your preferred normalization, **go back to the top of this routine and normalize the other sections** of your spectrum. You should have one _norm.xyz file for the red arm and two for the blue arm (blue1, blue 2)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c748c502",
   "metadata": {},
   "source": [
    "---\n",
    "# Calculate  and correct for Radial Velocity \n",
    "The following cells will open the files saved from the Normalization routine, and carry their modifications forward without saving them as files. This is why re-running any of the radial velocity correction cells more than once before restarting the kernel or switching input files will give near-zero radial velocities (the routine will radial-velocity correct spectra that has already been radial-velocity corrected!). \n",
    "\n",
    "The first cell in this routine indicates the saved files names and assigns the names of the output files. \n",
    "The second cell reads them out (the blue arm is stitched back together) and stores the three columns as a variable that can be modified using the SpecNormRV functions defined in the second cell of this notebook.\n",
    "The third cell plots the normalized red and blue arms found in the saved files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad5ac3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## UNCOMMENT IF YOU HAVE ALREADY CONTINUUM NORMALIZED DATA\n",
    "# Indicate the object and confirm file path.\n",
    "\n",
    "# Sag2_440_F: S20250401S0135, S20250423S0124, S20250423S0125\n",
    "\n",
    "# star = 'S20250130S0041' # 125, 126, 127\n",
    "# num  = '_001' # IFU\n",
    "# end  = '_dragons' + num  \n",
    "\n",
    "# path =  f'/astro/adovgal/GHOULS_DATA/' # Points to /FIXER_1\n",
    "# fipath = path  + f'Car2_208_A/' # This is the same path where output files will be saved\n",
    "# spath  = fipath + star                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc8ba14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naming of Files \n",
    "\n",
    "ftyp = 'xyz'\n",
    "blue1_spec_filename = spath + f'{num}_blue1_norm.{ftyp}' \n",
    "blue2_spec_filename = spath + f'{num}_blue2_norm.{ftyp}'\n",
    "blue_spec_filename  = spath + f'{num}_blue_norm'   \n",
    "red_spec_filename   = spath + f'{num}_red_norm.{ftyp}'    \n",
    "template_filename   = path  + 'FIXER_1/' + 'norm/metal_poor_template.spec.convol'\n",
    "rvnorm_blue         = spath + f'{num}_blue_normrv'\n",
    "rvnorm_red          = spath + f'{num}_red_normrv'\n",
    "radial_velocities   = spath + f'{num}_radialVelocities.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8d3e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the xyz files\n",
    "data_blue1 = np.genfromtxt(blue1_spec_filename, dtype = None, encoding = None, names = True)\n",
    "data_blue2 = np.genfromtxt(blue2_spec_filename, dtype = None, encoding = None, names = True)\n",
    "data_red   = np.genfromtxt(red_spec_filename,   dtype = None, encoding = None, names = True) \n",
    "\n",
    "data_blue1['variance'][data_blue1['variance']== 0.] = 1.e6\n",
    "data_blue2['variance'][data_blue2['variance']== 0.] = 1.e6\n",
    "data_red['variance'][data_red['variance'] == 0.]  = 1.e6\n",
    "\n",
    "data_blue1['flux'][~np.isfinite(data_blue1['flux'])]= 0.0\n",
    "data_blue2['flux'][~np.isfinite(data_blue2['flux'])]= 0.0\n",
    "data_red['flux'][~np.isfinite(data_red['flux'])]  = 0.0\n",
    "\n",
    "data_blue1['variance'][~np.isfinite(data_blue1['variance'])] = 1.e6\n",
    "data_blue2['variance'][~np.isfinite(data_blue2['variance'])] = 1.e6\n",
    "data_red['variance'][~np.isfinite(data_red['variance'])]   = 1.e6\n",
    "\n",
    "# Recobine the blue arm \n",
    "W,F,V = comb_blue(data_blue1, data_blue2)\n",
    "sa.write2xyz(W,F,V,blue_spec_filename)\n",
    "data_blue = np.genfromtxt(blue_spec_filename+'.xyz',dtype = None, encoding = None, names = True)\n",
    "\n",
    "# Feed to spectra to SpecNormRV function\n",
    "cand_blue1 = SpecNormRV(data_blue1['wavelength'], data_blue1['flux'], variance = data_blue1['variance'])\n",
    "cand_blue2 = SpecNormRV(data_blue2['wavelength'], data_blue2['flux'], variance = data_blue2['variance'])\n",
    "cand_red   = SpecNormRV(data_red['wavelength'],   data_red['flux'],   variance = data_red['variance'])\n",
    "cand_blue  = SpecNormRV(data_blue['wavelength'],  data_blue['flux'],  variance = data_blue['variance'])\n",
    "\n",
    "template = SpectrumTS(template_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db954836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot both arms \n",
    "%matplotlib notebook \n",
    "x = np.linspace(3500,9100,len(cand_red.wavelength))\n",
    "fig = plt.figure(figsize = (10,5))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_ylim(-2,15)\n",
    "ax.set_title(f'{star}{num} Normalized Spectrum')\n",
    "ax.set_ylabel('Normalized Flux')\n",
    "ax.set_xlabel('Wavelength [Å]')\n",
    "\n",
    "ax.plot(cand_blue.wavelength,cand_blue.flux, c='cornflowerblue', alpha= 0.7,label='Blue arm')\n",
    "ax.plot(cand_red.wavelength, cand_red.flux,  c='darkorange',alpha= 0.7, label='Red arm')\n",
    "\n",
    "ax.axhline(1, c='silver', linewidth=0.5, label='Flux = 1')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5fb5da",
   "metadata": {},
   "source": [
    "## Calculate RV from cross-correlation\n",
    "This step uses the metal poor template in \"norm\" to cross correlate with the input spectra over selected wavelength ranges. This cell uses 3 diferent ranges to estimate the star's radial velocity: \n",
    "- cand_blue1 spans the bluest region of the blue without including the noisy end\n",
    "- cand_blue2 spans from the end of blue1 to the red-most end\n",
    "- cand_blue is the region including both blue1 and blue2 (used for the spectrum rv correction, but not calculation)\n",
    "- cand_red2 is the bluest region of the red arm (used for rv correction)\n",
    "\n",
    "The velocity obtained for each region and its **fitting** errors are printed (in km/s)\n",
    "\n",
    "\n",
    "\n",
    "Re-run this cell with different ranges if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a51222",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Add the metal poor template \n",
    "cand_blue1.add_template(template) ; cand_blue2.add_template(template) ;\n",
    "cand_blue.add_template(template) ; cand_red.add_template(template) ;\n",
    "\n",
    "# =========================================================\n",
    "## Extra checks to see which regions fail with RV corrections:\n",
    "\n",
    "# Print out corrections for subregions and superregions\n",
    "RV_correct_many_regions = True\n",
    "# Print out corrections for specific lines\n",
    "RV_correct_many_lines   = True\n",
    "\n",
    "if RV_correct_many_regions == True:\n",
    "    correct_regions()\n",
    "    \n",
    "if RV_correct_many_lines == True:\n",
    "    correct_regions(specific_lines=True)\n",
    "    \n",
    "# =========================================================\n",
    "\n",
    "print(\"Corrections used for the final RV calculation:\")\n",
    "\n",
    "# The final corrections should all be close to each other.\n",
    "#  If not, adjust ranges until they are all similar.\n",
    "\n",
    "# Right now, the wavelength regimes correspond to blue1, blue23, red12, and blue123.\n",
    "# Normally you will NOT have to change these.\n",
    "formal_corrections = {\n",
    "    'blue_range1':[4000, 4400], # Must be within [4000,4400]  DEFAULT: [4000,4400]\n",
    "    'blue_range2':[4400, 5300], # Must be within [4400,5300]  DEFAULT: [4400,5300]\n",
    "    'red_range'  :[5300, 6500], # Must be within [5300,9000]  DEFAULT: [5300,6500]\n",
    "    'blue_range' :[4000, 5300]  # Must be within [4000,5300]  DEFAULT: [4000,5300]\n",
    "}\n",
    "\n",
    "\n",
    "print('blue1:  \\t{}\\t± {}'.format(*correct_RV_at_wrange(formal_corrections['blue_range1'])))\n",
    "print('blue23: \\t{}\\t± {}'.format(*correct_RV_at_wrange(formal_corrections['blue_range2'])))\n",
    "print('red12:  \\t{}\\t± {}'.format(*correct_RV_at_wrange(formal_corrections['red_range'])))\n",
    "\n",
    "print(\"\\nNot included for final RV calculation, but displays the RV correction applied to the blue arm for the output spectrum.\")\n",
    "print('blue123:\\t{}\\t± {}'.format(*correct_RV_at_wrange(formal_corrections['blue_range'], bfull=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7366bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the regions whose RV corrections will be saved to the radialVelocities.txt file\n",
    "lines_to_save = ['blue_range1', 'blue_range2', 'blue_range', 'red_range',\n",
    "                 'red_Ha', 'blue_MgB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a57edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(save_RV(lines_to_save))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee588f8",
   "metadata": {},
   "source": [
    "## Barycentric correction (OPTIONAL)\n",
    "The DRAGONS pipeline automatically does a barycentric correction which is why these cells are not used as code by default. However, for some of the commissioning files, DRAGONS is not able to perform the correction. If that is the case for your files, change the format of the following cell to code (from RAW) and use `True` in the save cell below it. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "f636f570",
   "metadata": {},
   "source": [
    "# Reads which IFU is being referenced \n",
    "if num == '_001':\n",
    "    nifu = 1\n",
    "elif num == '_002':\n",
    "    nifu = 2\n",
    "\n",
    "# Read the observation information from the _dragons.fits file headers (red and blue)  \n",
    "with fits.open(fipath+star+'_blue001_dragons.fits') as file:\n",
    "    header = file[0].header\n",
    "    blue_ra = header[f'IFU{nifu}RA']\n",
    "    blue_dec = header[f'IFU{nifu}DEC']\n",
    "    blue_exptime = header['EXPTIME']\n",
    "    blue_dateobs = header['DATE-OBS']\n",
    "    blue_utstart = header['UTSTART']\n",
    "\n",
    "blue_bary_data = [blue_ra, blue_dec, blue_dateobs, blue_utstart, blue_exptime]\n",
    "\n",
    "with fits.open(fipath+star+'_red001_dragons.fits') as file:\n",
    "    header = file[0].header\n",
    "    red_ra = header[f'IFU{nifu}RA']\n",
    "    red_dec = header[f'IFU{nifu}DEC']\n",
    "    red_exptime = header['EXPTIME']\n",
    "    red_dateobs = header['DATE-OBS']\n",
    "    red_utstart = header['UTSTART']\n",
    "    \n",
    "red_bary_data = [red_ra, red_dec, red_dateobs, red_utstart, red_exptime]\n",
    "\n",
    "# Print out corrections for subregions and superregions\n",
    "RV_correct_many_regions = True\n",
    "# Print out corrections for specific lines\n",
    "RV_correct_many_lines   = True\n",
    "\n",
    "if RV_correct_many_regions == True:\n",
    "    correct_regions(bary=True)\n",
    "    \n",
    "if RV_correct_many_lines == True:\n",
    "    correct_regions(specific_lines=True, bary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89c4f5e",
   "metadata": {},
   "source": [
    "### Save the radial velocities and their mean in a file for your reference. \n",
    "The following cell saves the radial velocities obtained for each of the wavelength ranges as well as a mean (printed) of the trusted ranges (typically blue1, blue2, red2) and corresponding uncertainties in a text file. **Note that the final uncertainty in radial velocity does not take into account the fitting uncertainties, due to assumptions made in uncertainty derivations. Instead, the final uncertainty is the standard deviation between the radial velocities of each of the three regions. However, the propagated error may be turned on with `include_quad_err = True`.** The cell also saves the radial-velocity corrected red and blue spectra for the IFU in .xyz files.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37683291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final RV corrected spectra:\n",
    "save_red = SpecNormRV(data_red['wavelength'],   data_red['flux'],   variance = data_red['variance'])\n",
    "save_blue = SpecNormRV(data_blue['wavelength'],  data_blue['flux'],  variance = data_blue['variance'])\n",
    "save_red.add_template(template) ; save_blue.add_template(template) ;\n",
    "save_red.rv_correct(wave_range=formal_corrections[\"red_range\"],  inspect = False, shift_wavelength=True)\n",
    "save_blue.rv_correct(wave_range=formal_corrections[\"blue_range\"], inspect = False, shift_wavelength=True)\n",
    "\n",
    "# Turn on barycentric velocity correction if required (TRUE vs FALSE). Off by default\n",
    "barycentric_velocity_correction = False \n",
    "\n",
    "# -----------------------------------------\n",
    "if barycentric_velocity_correction == True:\n",
    "    rv_blue1, rv_blue1_e = correct_RV_at_wrange(formal_corrections[\"blue_range1\"], bary=True)\n",
    "    rv_blue2, rv_blue2_e = correct_RV_at_wrange(formal_corrections[\"blue_range2\"], bary=True)\n",
    "    rv_red,   rv_red_e   = correct_RV_at_wrange(formal_corrections[\"red_range\"], bary=True) \n",
    "else: \n",
    "    rv_blue1, rv_blue1_e = correct_RV_at_wrange(formal_corrections[\"blue_range1\"])\n",
    "    rv_blue2, rv_blue2_e = correct_RV_at_wrange(formal_corrections[\"blue_range2\"])\n",
    "    rv_red,   rv_red_e   = correct_RV_at_wrange(formal_corrections[\"red_range\"])\n",
    "# -----------------------------------------\n",
    "\n",
    "# Indicate which radial_velocities you trust and their corresponding errors.\n",
    "rvs = [rv_blue1,rv_blue2,rv_red]\n",
    "rve = [rv_blue1_e,rv_blue2_e,rv_red_e]\n",
    "\n",
    "# -----------------------------------------\n",
    "mean_rv = sum(rvs)/len(rvs)\n",
    "rv_err  = np.std(rvs)\n",
    "\n",
    "rv_quad_err = np.sqrt(np.sum(np.array(rve)**2))\n",
    "include_quad_err = True\n",
    "\n",
    "# Formating and writing to the Text file \n",
    "Des = \"Radial velocities in km/s. Estimated by crosscorrelating sections of the spectrum with a metal poor template\\n\\n\"\n",
    "\n",
    "Top = save_RV(lines_to_save, barycentric_velocity_correction)\n",
    "\n",
    "Res = f'Mean RV:\\t{mean_rv}\\t± {rv_err}\\n'\n",
    "if include_quad_err == True:\n",
    "    Res += f'Error from sum in quadrature is:\\t± {rv_quad_err}\\n'\n",
    "Res += f'Computed with:{rvs}'\n",
    "\n",
    "# #================================================================================\n",
    "with open(radial_velocities,\"w\") as rv_results:\n",
    "    rv_results.write(Des+Top+Res)\n",
    "rv_results.close()   \n",
    "\n",
    "# Save the RV-corrected normalized spectrum for the Blue and Red arms (Separate)\n",
    "sa.write2xyz(save_blue.wavelength, save_blue.flux, save_blue.variance,rvnorm_blue)\n",
    "sa.write2xyz(save_red.wavelength, save_red.flux, save_red.variance,rvnorm_red)\n",
    "# #================================================================================\n",
    "\n",
    "# Show the mean radial velocity in km/s and the error\n",
    "print(mean_rv,'±',rv_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24634a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Des + Top + Res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea56d69",
   "metadata": {},
   "source": [
    "# Print out the blue & red normalized, RV corrected spectrum\n",
    "This cell reads the radial-velocity corrected files saved in the previous routine and plots the spectrum. It allows visualization of this notebook's final output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027e891b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "datab = np.genfromtxt(rvnorm_blue+'.xyz', dtype = None, encoding = None, names = True)\n",
    "datar = np.genfromtxt(rvnorm_red +'.xyz', dtype = None, encoding = None, names = True)\n",
    "\n",
    "fig = plt.figure(figsize = (10,5))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_ylim(-5,10)\n",
    "ax.set_title(f'{star}{num} RV-corrected normalized spectrum')\n",
    "ax.set_ylabel('Normalized Flux')\n",
    "ax.set_xlabel('Wavelength [Å]')\n",
    "\n",
    "ax.plot(datab['wavelength'], datab['flux'], c='cornflowerblue' , alpha= 0.7, label='Blue Arm')\n",
    "ax.plot(datar['wavelength'], datar['flux'], c='darkorange' , alpha= 0.7, label='Red Arm')\n",
    "\n",
    "x = np.linspace(3600,9200,10000)\n",
    "ax.plot(x,x*0+1,c=\"silver\",linewidth=0.5, label='Flux = 1')\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820be949",
   "metadata": {},
   "source": [
    "# Combining blue and red arms, also combining multiple epochs:\n",
    "\n",
    "If there are multiple epochs of observations (i.e. over the same, or multiple nights) for a single star, ensure that **each observation has been individually radial velocity corrected** before combining each observation and arm.\n",
    "\n",
    "In the directory containing all of the radial velocity corrected xyz files **for a single star** (with file suffix `normrv.xyz`), run the commands:\n",
    "\n",
    "`ls *normrv.xyz > xyz.txt`\n",
    "\n",
    "`cp xyz.txt fits.txt`\n",
    "\n",
    "`sed -i 's/xyz/fits/g' fits.txt`\n",
    "\n",
    "`vim combspec.txt` and input the name of the final output file, e.g. `star_name_normrv.fits`\n",
    "\n",
    "**xyz.txt** should contain the names of all of the spectra you wish to median-combine. **fits.txt** is the same, just with a `.fits` extension. Make sure that these do not contain spectra from more than one star.\n",
    "\n",
    "### (May also do `cl`, and then run the `epar` commands there, instead of `pyraf`)\n",
    "\n",
    "In `pyraf`, run:\n",
    "\n",
    "`epar rspectext` \n",
    "\n",
    "    input = @xyz.txt, output = @fits.txt, (flux) flux calibrated = No, (dtype) = interp\n",
    "    \n",
    "All other settings are default, click `Execute`\n",
    "\n",
    "`epar scombine`\n",
    "\n",
    "    input = @fits.txt, output = @combspec.txt, (group) = apertures, (combine) = median, (reject) = none\n",
    "    \n",
    "All other settings are default, click `Execute`\n",
    "\n",
    "Now you should have a continuum subtracted, RV-normalized spectrum spanning both the blue and red arms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3127b6c4",
   "metadata": {},
   "source": [
    "# Combining arms, step 1  automatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54ae263",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fipath)\n",
    "print(path)\n",
    "\n",
    "fipath = \"/your_path_to_data/\"\n",
    "\n",
    "star_id = 'STAR_NAME'\n",
    "\n",
    "\n",
    "# ================= Important chunk ====================\n",
    "os.system(f'ls {fipath}*normrv.xyz > {fipath}xyz.txt')\n",
    "os.system(f'cp {fipath}xyz.txt {fipath}fits.txt')\n",
    "os.system(f\"sed -i 's/xyz/fits/g' {fipath}fits.txt\")\n",
    "os.system(f'echo {star_id}_normrv.fits > {fipath}combspec.txt')\n",
    "\n",
    "# ============= if pyraf is installed: =================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e573ab59",
   "metadata": {},
   "source": [
    "# To flatten the final combined fits file to a 1D spectrum (.xy/.xyz):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d623dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "Path = '/your_path_to_data/'\n",
    "obj  = 'STAR_NAME'\n",
    "fullpath = Path + obj + '/'\n",
    "\n",
    "File = fullpath + obj + '_normrv.fits'\n",
    "\n",
    "ftyp = 'cfits'\n",
    "w, f = sa.read_spec(File, ftype = ftyp)\n",
    "#w,f,e = sa.read_spec(File, ftype = ftyp)\n",
    "\n",
    "w_min = 3700\n",
    "w_max = 9500\n",
    "ind = np.where( (w >= w_min) & (w <= w_max ) )[0]\n",
    "wave = w[ind]\n",
    "flux = np.array(f[ind].flatten(), dtype='float32')\n",
    "#error = np.array(e[ind].flatten(), dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c699d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = fullpath + obj +'_normrv'\n",
    "sa.write2xy(wave, flux, save_path)\n",
    "#sa.write2xyz(wave, flux, error, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939cd199",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
